{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,SimpleRNN,Embedding,Flatten\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "metadata": {
        "id": "js2MsE0f_H5n"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,y_train),(X_text,y_test) = imdb.load_data(num_words=10000)"
      ],
      "metadata": {
        "id": "X76bov2z_a8x"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8KyPiiL_sRQ",
        "outputId": "96a58067-4db1-41a1-b784-f7c23ab0f5d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "bwFmYNfV_7SJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "BH93WnUFAeCK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pad_sequences(X_train,padding='post',maxlen=50)\n",
        "X_text = pad_sequences(X_text,padding='post',maxlen=50)"
      ],
      "metadata": {
        "id": "jqDLDxYz_uRS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ2iRrWt_43E",
        "outputId": "ebbc515c-93a4-4b67-d160-1f0b51765b9e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "L3Tdyp31Av-q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.add(Embedding(input_dim=10000, output_dim=2, input_length=50))\n",
        "model.add(SimpleRNN(32,return_sequences=False))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.build(input_shape=(None, 50))  # batch_size can be None\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "XpV1JDXJA5Fn",
        "outputId": "6405693e-4773-4561-daed-c8df7949105c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m2\u001b[0m)          │        \u001b[38;5;34m20,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,153\u001b[0m (82.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,153</span> (82.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,153\u001b[0m (82.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,153</span> (82.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X_train,y_train,epochs=5,validation_data=(X_text,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEHMfiXRBCw7",
        "outputId": "d58ec0c4-227a-4156-e535-5f5332c27045"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 17ms/step - accuracy: 0.5205 - loss: 0.6921 - val_accuracy: 0.6045 - val_loss: 0.6519\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.7305 - loss: 0.5309 - val_accuracy: 0.7974 - val_loss: 0.4390\n",
            "Epoch 3/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.8620 - loss: 0.3318 - val_accuracy: 0.7998 - val_loss: 0.4414\n",
            "Epoch 4/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.8934 - loss: 0.2654 - val_accuracy: 0.8023 - val_loss: 0.5037\n",
            "Epoch 5/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.9136 - loss: 0.2211 - val_accuracy: 0.7984 - val_loss: 0.5031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7953ed51e450>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred=model.predict(X_text)\n",
        "print(pred)"
      ],
      "metadata": {
        "id": "ywYVdHeEB_SQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1698db6b-36dc-4bb5-b308-9c240ad257a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
            "[[0.02364939]\n",
            " [0.9702627 ]\n",
            " [0.76432186]\n",
            " ...\n",
            " [0.08659793]\n",
            " [0.04923705]\n",
            " [0.9059576 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNPHocc8Erkn",
        "outputId": "0831ae4a-b31c-4e47-e238-abd67b0155d0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(0.023649389)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = model.layers[0]  # Get the Embedding layer\n",
        "embedding_weights = embedding_layer.get_weights()[0]  # Shape: (10000, 2)\n",
        "print(embedding_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeepFHbxEx_A",
        "outputId": "8f2c5c4f-b78d-4d6e-c82d-093ef554b829"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.01234282 -0.0178585 ]\n",
            " [-0.09893288 -0.02909508]\n",
            " [ 0.00281908 -0.0023547 ]\n",
            " ...\n",
            " [-0.07629984 -0.0384614 ]\n",
            " [ 0.00024326  0.03264343]\n",
            " [-0.15335707 -0.1634919 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LlXHs-qGmTp",
        "outputId": "855210f5-da00-4a07-8c8d-cdd84989661c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 394,  354,    4,  123,    9, 1035, 1035, 1035,   10,   10,   13,\n",
              "         92,  124,   89,  488, 7944,  100,   28, 1668,   14,   31,   23,\n",
              "         27, 7479,   29,  220,  468,    8,  124,   14,  286,  170,    8,\n",
              "        157,   46,    5,   27,  239,   16,  179,    2,   38,   32,   25,\n",
              "       7944,  451,  202,   14,    6,  717], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# Load the IMDB word index\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# Reverse the word index to map integer indices to words\n",
        "index_to_word = {index: word for word, index in word_index.items()}\n",
        "\n",
        "# Get the embedding layer weights\n",
        "embedding_layer = model.layers[0]\n",
        "embedding_weights = embedding_layer.get_weights()[0]  # Shape: (10000, 2)\n",
        "\n",
        "# Example: Get the word and embedding for the first word in the first test sample\n",
        "sample_index = 0  # First test sample\n",
        "word_index_in_sequence = X_text[sample_index][0]  # First word in the sequence\n",
        "\n",
        "# Map the integer index to the word\n",
        "word = index_to_word.get(word_index_in_sequence, \"<UNKNOWN>\")\n",
        "print(f\"Word: {word}\")\n",
        "\n",
        "# Get the embedding vector for the word\n",
        "embedding_vector = embedding_weights[word_index_in_sequence]\n",
        "print(f\"Embedding vector: {embedding_vector}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4F_-ibmHcgl",
        "outputId": "0e63cd17-96c5-4f26-958b-c6d41c56e8f3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Word: getting\n",
            "Embedding vector: [0.2522821  0.19118622]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# 1. Load the IMDB word index (word -> integer mapping)\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# 2. Reverse it (integer -> word)\n",
        "index_to_word = {index: word for word, index in word_index.items()}\n",
        "\n",
        "# 3. Decode the first sentence in X_text\n",
        "first_sentence_indices = X_text[0]  # Get the first sentence (list of integers)\n",
        "first_sentence_words = []\n",
        "\n",
        "for index in first_sentence_indices:\n",
        "    # Indices 0, 1, 2 are reserved for padding, start token, and unknown\n",
        "    if index >= 3:  # Shift index by 3 since IMDB reserves first 3 indices\n",
        "        word = index_to_word.get(index - 3, \"?\")  # \"?\" if word not found\n",
        "    else:\n",
        "        word = \"?\"  # Unknown (padding/placeholder)\n",
        "    first_sentence_words.append(word)\n",
        "\n",
        "# Join the words to form the sentence\n",
        "first_sentence = \" \".join(first_sentence_words)\n",
        "print(\"First sentence in X_test:\")\n",
        "print(first_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZlz48QrHlRF",
        "outputId": "a15e330b-2d41-43c3-ba62-400fee4a859a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First sentence in X_test:\n",
            "terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite ? so all you madison fans give this a miss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# Load the IMDB word index\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# Reverse the word index to map integer indices to words\n",
        "index_to_word = {index: word for word, index in word_index.items()}\n",
        "\n",
        "# Get the first sentence (list of integer indices)\n",
        "first_sentence_indices = X_text[0]\n",
        "\n",
        "# Get the embedding layer weights (shape: [vocab_size, embedding_dim])\n",
        "embedding_layer = model.layers[0]\n",
        "embedding_weights = embedding_layer.get_weights()[0]\n",
        "\n",
        "# Print each word with its index and embedding vector\n",
        "print(\"First sentence with indices and embeddings:\")\n",
        "for position, index in enumerate(first_sentence_indices):\n",
        "    if index >= 3:  # IMDB reserves 0,1,2 for special tokens\n",
        "        word = index_to_word.get(index - 3, \"?\")  # Shift index by 3\n",
        "        vector = embedding_weights[index]\n",
        "    else:\n",
        "        word = \"?\"  # Placeholder for padding/unknown\n",
        "        vector = \"[PADDING]\"\n",
        "\n",
        "    print(f\"Position {position}: Index={index}, Word='{word}', Embedding={vector}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWeLeHJaI0N7",
        "outputId": "0d5ab12c-38d8-4b63-831c-deb79df3f178"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First sentence with indices and embeddings:\n",
            "Position 0: Index=394, Word='terrible', Embedding=[0.2522821  0.19118622]\n",
            "Position 1: Index=354, Word='performances', Embedding=[-0.03896452 -0.10041937]\n",
            "Position 2: Index=4, Word='the', Embedding=[-0.02859928 -0.01228904]\n",
            "Position 3: Index=123, Word='show', Embedding=[ 0.02203703 -0.04246587]\n",
            "Position 4: Index=9, Word='is', Embedding=[-0.01728423 -0.02527518]\n",
            "Position 5: Index=1035, Word='flat', Embedding=[ 0.11881304 -0.05880819]\n",
            "Position 6: Index=1035, Word='flat', Embedding=[ 0.11881304 -0.05880819]\n",
            "Position 7: Index=1035, Word='flat', Embedding=[ 0.11881304 -0.05880819]\n",
            "Position 8: Index=10, Word='br', Embedding=[ 0.00966143 -0.00535883]\n",
            "Position 9: Index=10, Word='br', Embedding=[ 0.00966143 -0.00535883]\n",
            "Position 10: Index=13, Word='i', Embedding=[-0.03384641 -0.00185681]\n",
            "Position 11: Index=92, Word='don't', Embedding=[-0.00356671  0.04518733]\n",
            "Position 12: Index=124, Word='know', Embedding=[-0.03642732 -0.0562656 ]\n",
            "Position 13: Index=89, Word='how', Embedding=[-0.07814115  0.04205132]\n",
            "Position 14: Index=488, Word='michael', Embedding=[-0.04090521 -0.04894782]\n",
            "Position 15: Index=7944, Word='madison', Embedding=[-0.04278193 -0.08824732]\n",
            "Position 16: Index=100, Word='could', Embedding=[0.00646509 0.09475287]\n",
            "Position 17: Index=28, Word='have', Embedding=[ 0.00967926 -0.0053991 ]\n",
            "Position 18: Index=1668, Word='allowed', Embedding=[0.02452222 0.007178  ]\n",
            "Position 19: Index=14, Word='this', Embedding=[0.0081583  0.03178952]\n",
            "Position 20: Index=31, Word='one', Embedding=[-0.00745977 -0.01437899]\n",
            "Position 21: Index=23, Word='on', Embedding=[0.01552945 0.02768398]\n",
            "Position 22: Index=27, Word='his', Embedding=[ 0.00192574 -0.04171826]\n",
            "Position 23: Index=7479, Word='plate', Embedding=[ 0.08796842 -0.01406551]\n",
            "Position 24: Index=29, Word='he', Embedding=[ 0.04001211 -0.09448183]\n",
            "Position 25: Index=220, Word='almost', Embedding=[-0.05942601 -0.04766551]\n",
            "Position 26: Index=468, Word='seemed', Embedding=[0.11356055 0.02458249]\n",
            "Position 27: Index=8, Word='to', Embedding=[0.01901824 0.01852308]\n",
            "Position 28: Index=124, Word='know', Embedding=[-0.03642732 -0.0562656 ]\n",
            "Position 29: Index=14, Word='this', Embedding=[0.0081583  0.03178952]\n",
            "Position 30: Index=286, Word='wasn't', Embedding=[0.12222547 0.03079152]\n",
            "Position 31: Index=170, Word='going', Embedding=[ 0.05619543 -0.00637241]\n",
            "Position 32: Index=8, Word='to', Embedding=[0.01901824 0.01852308]\n",
            "Position 33: Index=157, Word='work', Embedding=[-0.01594379 -0.03317611]\n",
            "Position 34: Index=46, Word='out', Embedding=[-0.00438494 -0.00363293]\n",
            "Position 35: Index=5, Word='and', Embedding=[-0.03099152 -0.00282552]\n",
            "Position 36: Index=27, Word='his', Embedding=[ 0.00192574 -0.04171826]\n",
            "Position 37: Index=239, Word='performance', Embedding=[ 0.03585152 -0.01735809]\n",
            "Position 38: Index=16, Word='was', Embedding=[0.05752007 0.00504502]\n",
            "Position 39: Index=179, Word='quite', Embedding=[-0.04658168 -0.05409258]\n",
            "Position 40: Index=2, Word='?', Embedding=[PADDING]\n",
            "Position 41: Index=38, Word='so', Embedding=[-0.02165921  0.01440627]\n",
            "Position 42: Index=32, Word='all', Embedding=[ 0.00773572 -0.0474958 ]\n",
            "Position 43: Index=25, Word='you', Embedding=[-0.0079278  -0.04252207]\n",
            "Position 44: Index=7944, Word='madison', Embedding=[-0.04278193 -0.08824732]\n",
            "Position 45: Index=451, Word='fans', Embedding=[-0.02672701  0.00940374]\n",
            "Position 46: Index=202, Word='give', Embedding=[ 0.05326424 -0.02058177]\n",
            "Position 47: Index=14, Word='this', Embedding=[0.0081583  0.03178952]\n",
            "Position 48: Index=6, Word='a', Embedding=[-0.03694028  0.00742246]\n",
            "Position 49: Index=717, Word='miss', Embedding=[ 0.08517568 -0.26834723]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeKwFXjAJUnS",
        "outputId": "d6b873bf-ddfb-4267-fc8b-8d9f758dfa75"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 394,  354,    4,  123,    9, 1035, 1035, 1035,   10,   10,   13,\n",
              "         92,  124,   89,  488, 7944,  100,   28, 1668,   14,   31,   23,\n",
              "         27, 7479,   29,  220,  468,    8,  124,   14,  286,  170,    8,\n",
              "        157,   46,    5,   27,  239,   16,  179,    2,   38,   32,   25,\n",
              "       7944,  451,  202,   14,    6,  717], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8lX_HVLlJV4a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}